<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="profile" href="https://gmpg.org/xfn/11">
<link rel="pingback" href="https://das2020.vlrlab.net/xmlrpc.php">
<title>Keynote Speeches &#8211; DAS 2020</title>
<link rel='dns-prefetch' href='https://fonts.googleapis.com/' />
<link rel='dns-prefetch' href='https://s.w.org/' />
<link rel="alternate" type="application/rss+xml" title="DAS 2020 &raquo; Feed" href="../feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="DAS 2020 &raquo; 评论Feed" href="../comments/feed/index.html" />
<script type="32259050b5a7e005f0e2a147-text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/12.0.0-1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/12.0.0-1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/das2020.vlrlab.net\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.4.10"}};
			/*! This file is auto-generated */
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='../wp-includes/css/dist/block-library/style.min.css%3Fver=5.4.10.css' type='text/css' media='all' />
<link rel='stylesheet' id='square-fonts-css' href='https://fonts.googleapis.com/css?family=Open+Sans%3A400%2C300%2C600%2C700%7CRoboto+Condensed%3A300italic%2C400italic%2C700italic%2C400%2C300%2C700&amp;subset=latin%2Clatin-ext' type='text/css' media='all' />
<link rel='stylesheet' id='bxslider-css' href='../wp-content/themes/square/css/jquery.bxslider.css%3Fver=4.1.2.css' type='text/css' media='all' />
<link rel='stylesheet' id='animate-css' href='../wp-content/themes/square/css/animate.css%3Fver=1.0.css' type='text/css' media='all' />
<link rel='stylesheet' id='font-awesome-css' href='../wp-content/themes/square/css/font-awesome.css%3Fver=4.6.3.css' type='text/css' media='all' />
<link rel='stylesheet' id='owl-carousel-css' href='../wp-content/themes/square/css/owl.carousel.css%3Fver=1.3.3.css' type='text/css' media='all' />
<link rel='stylesheet' id='owl-theme-css' href='../wp-content/themes/square/css/owl.theme.css%3Fver=1.3.3.css' type='text/css' media='all' />
<link rel='stylesheet' id='square-style-css' href='../wp-content/themes/square/style.css%3Fver=5.4.10.css' type='text/css' media='all' />
<script type="32259050b5a7e005f0e2a147-text/javascript" src='../wp-includes/js/jquery/jquery.js%3Fver=1.12.4-wp'></script>
<script type="32259050b5a7e005f0e2a147-text/javascript" src='../wp-includes/js/jquery/jquery-migrate.min.js%3Fver=1.4.1'></script>
<link rel='https://api.w.org/' href='../wp-json/index.html' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="../xmlrpc.php%3Frsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="../wp-includes/wlwmanifest.xml" />
<meta name="generator" content="WordPress 5.4.10" />
<link rel="canonical" href="../index.html%3Fp=713.html" />
<link rel='shortlink' href='../index.html%3Fp=713.html' />
<link rel="alternate" type="application/json+oembed" href="../wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fdas2020.vlrlab.net%252Fkeynote-speeches%252F" />
<link rel="alternate" type="text/xml+oembed" href="../wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fdas2020.vlrlab.net%252Fkeynote-speeches%252F&amp;format=xml" />
<style>.sq-main-header{background-image: url(https://www.vlrlab.net/das2020/docs/2019/09/微信图片_20190916124343.png)}</style><style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style></head>
<body class="page-template-default page page-id-713 sq_no_sidebar_condensed">
<div id="sq-page">
<header id="sq-masthead" class="sq-site-header sq-black">
<div class="sq-container sq-clearfix">
<div id="sq-site-branding">
<p class="sq-site-title"><a href="../index.html" rel="home">DAS 2020</a></p>
<p class="sq-site-description">Wuhan, China</p>
</div>
<div class="sq-toggle-nav">
<span></span>
</div>
<nav id="sq-site-navigation" class="sq-main-navigation">
<div class="sq-menu sq-clearfix"><ul id="menu-das2020" class="sq-clearfix"><li id="menu-item-1364" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1364"><a href="../index.html">Home</a></li>
<li id="menu-item-1367" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1367"><a href="../index.html%3Fp=174.html">Information</a>
<ul class="sub-menu">
<li id="menu-item-1390" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1390"><a href="../index.html%3Fp=174.html">Committees</a></li>
<li id="menu-item-1375" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1375"><a href="../index.html%3Fp=91.html">News</a></li>
</ul>
</li>
<li id="menu-item-1379" class="menu-item menu-item-type-post_type menu-item-object-page current-menu-ancestor current-menu-parent current_page_parent current_page_ancestor menu-item-has-children menu-item-1379"><a href="../index.html%3Fp=139.html">Program</a>
<ul class="sub-menu">
<li id="menu-item-1520" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1520"><a href="../index.html%3Fp=139.html">Program</a></li>
<li id="menu-item-1374" class="menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-713 current_page_item menu-item-1374"><a href="../index.html%3Fp=713.html" aria-current="page">Keynote Speakers</a></li>
<li id="menu-item-2233" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2233"><a href="../index.html%3Fp=2222.html">Tutorial</a></li>
<li id="menu-item-2426" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2426"><a href="../index.html%3Fp=2420.html">Awards</a></li>
</ul>
</li>
<li id="menu-item-1366" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1366"><a href="../index.html%3Fp=648.html">For authors</a>
<ul class="sub-menu">
<li id="menu-item-1391" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1391"><a href="../index.html%3Fp=648.html">Call for papers</a></li>
<li id="menu-item-1377" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1377"><a href="../index.html%3Fp=719.html">Paper Submission Instruction</a></li>
<li id="menu-item-1575" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1575"><a href="../index.html%3Fp=1573.html">Camera-Ready Submission Instruction</a></li>
<li id="menu-item-1653" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1653"><a href="../index.html%3Fp=1622.html">List of Accepted Articles</a></li>
<li id="menu-item-2353" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2353"><a href="../index.html%3Fp=2349.html">Presentation Instruction</a></li>
</ul>
</li>
<li id="menu-item-1380" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1380"><a href="../index.html%3Fp=88.html">Attending</a>
<ul class="sub-menu">
<li id="menu-item-1516" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1516"><a href="../index.html%3Fp=88.html">Registration</a></li>
<li id="menu-item-1531" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1531"><a href="../index.html%3Fp=102.html">Venue and Transportation</a></li>
<li id="menu-item-1383" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1383"><a href="../index.html%3Fp=100.html">Tours Option</a></li>
</ul>
</li>
<li id="menu-item-1382" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1382"><a href="../index.html%3Fp=813.html">Sponsorship</a></li>
<li id="menu-item-1368" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1368"><a href="../index.html%3Fp=830.html">Contact us</a></li>
</ul></div> </nav>
</div>
</header>
<div id="sq-content" class="sq-site-content sq-clearfix">
<header class="sq-main-header">
<div class="sq-container">
<h1 class="sq-main-title">Keynote Speeches</h1> </div>
</header>
<div class="sq-container sq-clearfix">
<div id="primary" class="content-area">
<main id="main" class="site-main" role="main">
<article id="post-713" class="sq-hentry post-713 page type-page status-publish">
<div class="entry-content single-entry-content">
<div id="pl-gb713-625a8a7b4d65f" class="panel-layout"><div id="pg-gb713-625a8a7b4d65f-0" class="panel-grid panel-no-style"><div id="pgc-gb713-625a8a7b4d65f-0-0" class="panel-grid-cell"><div id="panel-gb713-625a8a7b4d65f-0-0-0" class="so-panel widget widget_text panel-first-child panel-last-child" data-index="0"> <div class="textwidget"><p><strong><img class="wp-image-1260 size-full alignleft" src="https://www.vlrlab.net/das2020/docs/2020/01/Tong-Sun.png" alt="" width="162" height="198" /></strong></p>
<p><em><strong id="keynote1">Dr. Tong Sun</strong></em></p>
<p><strong>Document Intelligence Lab in Adobe</strong></p>
<p><strong>Title: The Future of Document: A New Frontier in the New Decade</strong></p>
<p><strong>Biography:</strong> <strong>Dr. Tong Sun</strong> is leading Document Intelligence Lab in Adobe to reinvent the document of the future in the era of AI and machine learning. Tong is a seasoned technology innovator and thought-leader with a 15+ years leadership in incubating new concepts through state-of-art scalable machine learning methods and tools, developing impactful rapid prototypes, and delivering competitive technologies to market opportunities in cross-disciplinary and cross-functional team environments. Her research interests on natural language processing and understanding, distributed machine learning, big data computing and human computer interaction. She held 22 issued US patents, 40+ peer-reviewed publications in prestigious conferences and journals. Prior to joining Adobe, Tong was the Director of Scalable Data Analytics Research Lab at Xerox PARC and the Group Leader of Decision Support and Machine Intelligence at United Technologies Research Center.</p>
<p><strong>Abstract:</strong> Documents have been an integral part of our day-to-day business for centuries. Today’s enterprises leverage documents to drive all essential and business critical processes and functions. Over past three decades, several paradigm shifts have reshaped the ways in which human interacts with documents: (1) the transition from paper to digital documents in 1990s (2) the always-on always-connected social media and mobile device in 2000s that enable people to access, share and collaborate instantly with documents; (3) the rise and widening success of AI and machine learning technologies in 2010s that unlocks intelligence from documents for deeper automation . At the dawn of 2020s, the new decade presents us with unprecedented challenges and opportunities: What the emerging disruptive trends are? Where the future of document is heading to? What key research questions we need to tackle in order to invent the document of the future? We truly believe the future of document lies in the conjunction of three aspects: deep structural and semantic understanding, the novel content format for next-generation infrastructure, and the magical user experiences with documents enabled by emerging technologies. In this talk, I will share our state of art research spans multi-modal document understanding, content forensic and trustworthy document and futuristic human-document interactions (e.g. editing, annotating, reading, collaboration) in mixed-reality and cross-modal interfaces.</p>
<p>&nbsp;</p>
</div>
</div></div></div></div>
<div id="pl-gb713-625a8a7b4d92a" class="panel-layout"><div id="pg-gb713-625a8a7b4d92a-0" class="panel-grid panel-has-style"><div class="panel-row-style panel-row-style-for-gb713-625a8a7b4d92a-0"><div id="pgc-gb713-625a8a7b4d92a-0-0" class="panel-grid-cell"><div id="panel-gb713-625a8a7b4d92a-0-0-0" class="so-panel widget widget_text panel-first-child panel-last-child" data-index="0"> <div class="textwidget"><p><strong><img class=" wp-image-1244 alignleft" src="http://www.vlrlab.net/das2020/docs/2020/01/微信图片_20200115120758.png" alt="" width="162" height="198" /></strong></p>
<p><em><strong id="keynote2">Prof. Lianwen Jin</strong></em></p>
<p><strong>South China University of Technology</strong></p>
<p><strong>Title: Optical Character Recognition in the Deep Learning Era</strong></p>
<p><strong>Biography:  Lianwen Jin</strong> received the B.S. degree from the University of Science and Technology of China, Anhui, China, and the Ph.D. degree from the South China University of Technology, Guangzhou, China, in 1991 and 1996, respectively. He is currently a Professor with the School of Electronic and Information Engineering, South China University of Technology. He is the author of more than 200 scientific papers. Dr. Jin was a recipient of the award of New Century Excellent Talent Program of MOE in 2006 and the Guangdong Pearl River Distinguished Professor Award in 2011. His research interests include optical character recognition, handwriting analysis and recognition, machine learning, deep learning, and computer vision.</p>
<p><strong>Abstract</strong>:  As one of the most fundamental and influential inventions of humanity, text has played an important role in human life. Rich and precise semantic information carried by the text is important in a wide range of vision-based application scenarios, such as image searching, image understanding, industrial automation, information security, instant translation, intelligent finance, robot navigation and so on. In recent years, with the fast development of deep learning theory and technology, optical character recognition (OCR) has been achieved great progress in many aspects such as unconstraint handwritten text recognition, camera based printed document analysis and recognition, scene text detection and recognition in the wild and so on. The OCR technology has also attracted extensive attention by both academia and industry and it plays a crucial role in many real-world AI systems. In this talk, I will briefly introduce the state-of-the-art of various deep learning methods in the field of OCR, and specifically introduce the main research progress in handwritten text recognition, signature verification and writer identification, and scene text detection and recognition. I will also discuss about some unsolved problems, new research topics and challenges, and future research trends.</p>
<p><strong>Biography:  Lianwen Jin</strong> received the B.S. degree from the University of Science and Technology of China, Anhui, China, and the Ph.D. degree from the South China University of Technology, Guangzhou, China, in 1991 and 1996, respectively. He is currently a Professor with the School of Electronic and Information Engineering, South China University of Technology. He is the author of more than 200 scientific papers. Dr. Jin was a recipient of the award of New Century Excellent Talent Program of MOE in 2006 and the Guangdong Pearl River Distinguished Professor Award in 2011. His research interests include optical character recognition, handwriting analysis and recognition, machine learning, deep learning, and computer vision.</p>
</div>
</div></div></div></div></div>
<div id="pl-gb713-625a8a7b4db49" class="panel-layout"><div id="pg-gb713-625a8a7b4db49-0" class="panel-grid panel-no-style"><div id="pgc-gb713-625a8a7b4db49-0-0" class="panel-grid-cell"><div id="panel-gb713-625a8a7b4db49-0-0-0" class="so-panel widget widget_text panel-first-child panel-last-child" data-index="0"> <div class="textwidget"><p>&nbsp;</p>
<p><em><strong id="keynote3">Prof. C.V. Jawahar</strong></em><em><strong><img class=" wp-image-2276 alignleft" src="https://www.vlrlab.net/das2020/docs/微信图片_20200511182122.png" alt="" width="162" height="198" /></strong></em></p>
<p><strong>IIIT Hyderabad, India</strong></p>
<p><strong>Title: Document Understanding Beyond Text Recognition</strong></p>
<p><strong>Biography:</strong>  <strong>Prof. C.V. Jawahar</strong> holds the Amazon Chair at the IIIT Hyderabad, India, where he leads a group focusing on computer vision, machine learning and multimedia systems. In the recent years, he has been looking into a set of problems that overlap with vision, language and text, as well as large scale multimedia retrieval systems. He has many publications in top-tier computer vision, robotics and document image processing conferences, with contributions in the areas of scene text understanding, Indian language OCRs and handwritten text recognition among others. Presently, he is an area editor of CVIU and an associate editor of IEEE PAMI. He is a Fellow of IAPR and INAE.</p>
<p><strong>Abstract:</strong> Abstract: The fundamental problem in document understanding has been the recognition of textual content present in the document images. Recent years have seen great advance in text recognition performance with innovative deep learning architectures. This may be the time to catch up with the other information rich  components that are present in the document image.  This include objects like tables, figures, equations and roles of text as captions and headings. Semantic understanding of the documents will be highly limited, if we do not understand these objects and cues. Segmentation should no longer be the necessary evil before the text recognition. The innovations in document image designs also leading to the reduction in the gap between the classical natural image understanding and the modern document image understanding.  This talks aims to peep into this emerging space and discuss the research directions and recent advances.</p>
</div>
</div></div></div></div>
<p></p>
</div>
<footer class="entry-footer">
</footer>
</article>
</main>
</div>
</div>
</div>
<footer id="sq-colophon" class="sq-site-footer">
<div id="sq-bottom-footer">
<div class="sq-container sq-clearfix">
<div class="sq-site-info">
<span class="sep"> | </span>
<a target="_blank" href="http://yx.100innovate.com">©DAS2020</a> </div>
<div class="sq-site-social">
</div>
</div>
</div>
</footer>
</div>
<style type="text/css" media="all" id="siteorigin-panels-layouts-footer">/* Layout gb713-625a8a7b4d65f */ #pgc-gb713-625a8a7b4d65f-0-0 { width:100%;width:calc(100% - ( 0 * 30px ) ) } #pl-gb713-625a8a7b4d65f .so-panel { margin-bottom:30px } #pl-gb713-625a8a7b4d65f .so-panel:last-child { margin-bottom:0px } #pg-gb713-625a8a7b4d65f-0.panel-no-style, #pg-gb713-625a8a7b4d65f-0.panel-has-style > .panel-row-style { -webkit-align-items:flex-start;align-items:flex-start } @media (max-width:780px){ #pg-gb713-625a8a7b4d65f-0.panel-no-style, #pg-gb713-625a8a7b4d65f-0.panel-has-style > .panel-row-style { -webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column } #pg-gb713-625a8a7b4d65f-0 > .panel-grid-cell , #pg-gb713-625a8a7b4d65f-0 > .panel-row-style > .panel-grid-cell { width:100%;margin-right:0 } #pl-gb713-625a8a7b4d65f .panel-grid-cell { padding:0 } #pl-gb713-625a8a7b4d65f .panel-grid .panel-grid-cell-empty { display:none } #pl-gb713-625a8a7b4d65f .panel-grid .panel-grid-cell-mobile-last { margin-bottom:0px }  } /* Layout gb713-625a8a7b4d92a */ #pgc-gb713-625a8a7b4d92a-0-0 { width:100%;width:calc(100% - ( 0 * 30px ) ) } #pl-gb713-625a8a7b4d92a .so-panel { margin-bottom:30px } #pl-gb713-625a8a7b4d92a .so-panel:last-child { margin-bottom:0px } #pg-gb713-625a8a7b4d92a-0> .panel-row-style { padding:0px 0px 0px 0px } #pg-gb713-625a8a7b4d92a-0.panel-no-style, #pg-gb713-625a8a7b4d92a-0.panel-has-style > .panel-row-style { -webkit-align-items:flex-start;align-items:flex-start } @media (max-width:780px){ #pg-gb713-625a8a7b4d92a-0.panel-no-style, #pg-gb713-625a8a7b4d92a-0.panel-has-style > .panel-row-style { -webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column } #pg-gb713-625a8a7b4d92a-0 > .panel-grid-cell , #pg-gb713-625a8a7b4d92a-0 > .panel-row-style > .panel-grid-cell { width:100%;margin-right:0 } #pl-gb713-625a8a7b4d92a .panel-grid-cell { padding:0 } #pl-gb713-625a8a7b4d92a .panel-grid .panel-grid-cell-empty { display:none } #pl-gb713-625a8a7b4d92a .panel-grid .panel-grid-cell-mobile-last { margin-bottom:0px }  } /* Layout gb713-625a8a7b4db49 */ #pgc-gb713-625a8a7b4db49-0-0 { width:100%;width:calc(100% - ( 0 * 30px ) ) } #pl-gb713-625a8a7b4db49 .so-panel { margin-bottom:30px } #pl-gb713-625a8a7b4db49 .so-panel:last-child { margin-bottom:0px } #pg-gb713-625a8a7b4db49-0.panel-no-style, #pg-gb713-625a8a7b4db49-0.panel-has-style > .panel-row-style { -webkit-align-items:flex-start;align-items:flex-start } @media (max-width:780px){ #pg-gb713-625a8a7b4db49-0.panel-no-style, #pg-gb713-625a8a7b4db49-0.panel-has-style > .panel-row-style { -webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column } #pg-gb713-625a8a7b4db49-0 > .panel-grid-cell , #pg-gb713-625a8a7b4db49-0 > .panel-row-style > .panel-grid-cell { width:100%;margin-right:0 } #pl-gb713-625a8a7b4db49 .panel-grid-cell { padding:0 } #pl-gb713-625a8a7b4db49 .panel-grid .panel-grid-cell-empty { display:none } #pl-gb713-625a8a7b4db49 .panel-grid .panel-grid-cell-mobile-last { margin-bottom:0px }  } </style><link rel='stylesheet' id='siteorigin-panels-front-css' href='../wp-content/plugins/siteorigin-panels/css/front-flex.min.css%3Fver=2.11.0.css' type='text/css' media='all' />
<script type="32259050b5a7e005f0e2a147-text/javascript" src='../wp-content/themes/square/js/modernizr.js%3Fver=2.6.3'></script>
<script type="32259050b5a7e005f0e2a147-text/javascript" src='../wp-content/themes/square/js/jquery.bxslider.js%3Fver=4.1.2'></script>
<script type="32259050b5a7e005f0e2a147-text/javascript" src='../wp-content/themes/square/js/owl.carousel.js%3Fver=1.3.3'></script>
<script type="32259050b5a7e005f0e2a147-text/javascript" src='../wp-content/themes/square/js/jquery.superfish.js%3Fver=20160213'></script>
<script type="32259050b5a7e005f0e2a147-text/javascript" src='../wp-content/themes/square/js/square-custom.js%3Fver=20150903'></script>
<script type="32259050b5a7e005f0e2a147-text/javascript" src='../wp-includes/js/wp-embed.min.js%3Fver=5.4.10'></script>
<script src="../cdn-cgi/scripts/7d0fa10a/cloudflare-static/rocket-loader.min.js" data-cf-settings="32259050b5a7e005f0e2a147-|49" defer=""></script></body>
</html>
